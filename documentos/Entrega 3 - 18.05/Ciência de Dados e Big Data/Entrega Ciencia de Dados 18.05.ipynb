{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6874f185-708f-463c-8329-a802c5fb466b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a1cafe-c73e-4ed4-bf08-c8d3040e9578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Local\\Temp\\ipykernel_12516\\3639340257.py:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dfEstimadaSelecionada = dfEstimadaComProduto.groupby(\"RideID\").apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Exemplo de dados do dfDerivado com estimativas:\n",
      "    RideID  Dia  Hora  Minuto  HoraDecimal          Faixa15min       Lat1  \\\n",
      "0  1183200    1    10       9    10.150000 2021-08-17 10:00:00 -26.329754   \n",
      "1  1183201    1    10       9    10.150000 2021-08-17 10:00:00 -27.491979   \n",
      "2  1183202    1    10      10    10.166667 2021-08-17 10:00:00 -19.849580   \n",
      "3  1183203    1    10      10    10.166667 2021-08-17 10:00:00 -23.962423   \n",
      "4  1183204    1    10      10    10.166667 2021-08-17 10:00:00 -10.919802   \n",
      "5  1183205    1    10      10    10.166667 2021-08-17 10:00:00 -22.873502   \n",
      "6  1183206    1    10      10    10.166667 2021-08-17 10:00:00 -23.554281   \n",
      "7  1183207    1    10      10    10.166667 2021-08-17 10:00:00 -23.962423   \n",
      "8  1183208    1    10      10    10.166667 2021-08-17 10:00:00 -19.849539   \n",
      "9  1183209    1    10      10    10.166667 2021-08-17 10:00:00  -8.025771   \n",
      "\n",
      "        Lng1                                        AddressOrig       Lat2  \\\n",
      "0 -48.840428  Rua Jo√£o Pinheiro, 585 - Rua Jo√£o Pinheiro - B... -26.255466   \n",
      "1 -48.528288  Rodovia Rafael da Rocha Pires, 1883 - Rodovia ... -27.437149   \n",
      "2 -44.019916  Rua Bar√£o do Rio Branco, 12 - Rua Bar√£o do Rio... -19.936899   \n",
      "3 -46.254658               Tv. Duzentos e Sessenta e Um, 72, 72 -23.837307   \n",
      "4 -37.077442        Rua Argentina, 160 - Rua Argentina - Brasil -10.907129   \n",
      "5 -43.571402  Rua Jo√£o Cir√≠lo de Oliveira, 5 - Rua Jo√£o Cir√≠... -22.917373   \n",
      "6 -46.662732  Avenida Ang√©lica, 2573 - Avenida Ang√©lica - Br... -23.734290   \n",
      "7 -46.254658               Tv. Duzentos e Sessenta e Um, 72, 72 -23.837307   \n",
      "8 -44.019929  R. Bar√£o do Rio Branco, 12 - Nacional, Contage... -19.936899   \n",
      "9 -34.874475   Rua Jo√£o Alfredo, 83 - Rua Jo√£o Alfredo - Brasil  -8.029684   \n",
      "\n",
      "        Lng2                                        AddressDest  \\\n",
      "0 -48.643420  Av. Dr. Nereu Ramos, 450 - Rocio Grande, S√£o F...   \n",
      "1 -48.398243  Angeloni Ingleses (Florian√≥polis) - Supermerca...   \n",
      "2 -43.940160  R. Ant√¥nio de Albuquerque, 1080 - Funcion√°rios...   \n",
      "3 -46.132172                 Semar Supermercados Bertioga, 2141   \n",
      "4 -37.087719  R. Sime√£o Aguiar, 430 - Novo Para√≠so, Aracaju ...   \n",
      "5 -43.633044  Av. Ces√°rio de Melo, 10809 - Paci√™ncia, Rio de...   \n",
      "6 -46.698628  Av. Sen. Teot√¥nio Vilela, 4029 - Parque Cocaia...   \n",
      "7 -46.132172                 Semar Supermercados Bertioga, 2141   \n",
      "8 -43.940160  R. Ant√¥nio de Albuquerque, 1080 - Funcion√°rios...   \n",
      "9 -34.944037  Av. Professor Joaquim Cavalcanti, 721 - Iputin...   \n",
      "\n",
      "                                         Estimativas  Distancia_km  \n",
      "0  {'Flash': 89.0, 'UberX': 89.0, 'Comfort': 116....     21.327034  \n",
      "1  {'Flash': 31.5, 'Comfort': 33.5, '99POUPA': 26...     14.217724  \n",
      "2  {'Moto': 25.5, 'Comfort': 44.0, 'UberFlash': 4...     12.774740  \n",
      "3  {'Flash': 47.5, '99POP': 63.69, 'Comfort': 68....     18.644013  \n",
      "4  {'99POUPA': 7.88, '99POP': 7.88, '99TAXI': 17....      1.796461  \n",
      "5  {'99POUPA': 14.69, '99POP': 19.51, '99TAXI': 5...      7.975203  \n",
      "6  {'UberX': 46.5, 'Comfort': 71.5, 'Flash': 43.0...     20.270171  \n",
      "7  {'99TAXI': 118.16, 'T√°xi Comum': 138.95, 'Flas...     18.644013  \n",
      "8  {'99POUPA': 71.3, '99POP': 71.3, '99TAXI': 62....     12.779065  \n",
      "9  {'Flash': 18.0, 'Flash Moto': 12.0, 'Comfort':...      7.680426  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. Carregamento dos arquivos\n",
    "dfRide = pd.read_csv(\"ride_v2.csv\", sep=\";\", dtype=str)\n",
    "dfRideAdd = pd.read_csv(\"rideaddress_v1.csv\", sep=\";\", dtype=str)\n",
    "dfRideEst = pd.read_csv(\"rideestimative_v3.csv\", sep=\";\", dtype=str)\n",
    "dfProduct = pd.read_csv(\"product.csv\", sep=\";\", dtype=str)\n",
    "\n",
    "# 2. Uniformiza√ß√£o: datas e RideID\n",
    "dfRide[\"Schedule\"] = pd.to_datetime(dfRide[\"Schedule\"], errors=\"coerce\")\n",
    "for df in [dfRide, dfRideAdd, dfRideEst]:\n",
    "    df[\"RideID\"] = df[\"RideID\"].astype(str).str.replace(\".0\", \"\", regex=False)\n",
    "\n",
    "# 3. Derivar colunas de tempo\n",
    "dfRide[\"Dia\"] = dfRide[\"Schedule\"].dt.weekday\n",
    "dfRide[\"Hora\"] = dfRide[\"Schedule\"].dt.hour\n",
    "dfRide[\"Minuto\"] = dfRide[\"Schedule\"].dt.minute\n",
    "dfRide[\"HoraDecimal\"] = dfRide[\"Hora\"] + dfRide[\"Minuto\"] / 60\n",
    "dfRide[\"Faixa15min\"] = dfRide[\"Schedule\"].dt.floor(\"15min\")\n",
    "dfTempo = dfRide[[\"RideID\", \"Dia\", \"Hora\", \"Minuto\", \"HoraDecimal\", \"Faixa15min\"]].dropna()\n",
    "\n",
    "# 4. Extrair origem e destino (Lat, Lng, Address)\n",
    "dfRideAdd = dfRideAdd.rename(columns={\"RideAddressTypeID\": \"OrigDest\"})\n",
    "dfOrigem = dfRideAdd[dfRideAdd[\"OrigDest\"] == \"1\"][[\"RideID\", \"Lat\", \"Lng\", \"Address\"]].rename(\n",
    "    columns={\"Lat\": \"Lat1\", \"Lng\": \"Lng1\", \"Address\": \"AddressOrig\"}\n",
    ")\n",
    "dfDestino = dfRideAdd[dfRideAdd[\"OrigDest\"] == \"2\"][[\"RideID\", \"Lat\", \"Lng\", \"Address\"]].rename(\n",
    "    columns={\"Lat\": \"Lat2\", \"Lng\": \"Lng2\", \"Address\": \"AddressDest\"}\n",
    ")\n",
    "dfCoords = pd.merge(dfOrigem, dfDestino, on=\"RideID\", how=\"inner\")\n",
    "\n",
    "# Corrige v√≠rgulas e converte coordenadas\n",
    "for col in [\"Lat1\", \"Lng1\", \"Lat2\", \"Lng2\"]:\n",
    "    dfCoords[col] = dfCoords[col].str.replace(\",\", \".\").astype(float).round(6)\n",
    "\n",
    "# 5. Integrar todas as estimativas com produtos em UMA COLUNA tipo dicion√°rio\n",
    "dfRideEst[\"ProductID\"] = dfRideEst[\"ProductID\"].astype(str)\n",
    "dfProduct[\"ProductID\"] = dfProduct[\"ProductID\"].astype(str)\n",
    "\n",
    "dfEstimadaComProduto = pd.merge(dfRideEst, dfProduct, on=\"ProductID\", how=\"left\")\n",
    "dfEstimadaComProduto[\"Price\"] = dfEstimadaComProduto[\"Price\"].str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "dfEstimadaSelecionada = dfEstimadaComProduto.groupby(\"RideID\").apply(\n",
    "    lambda x: dict(zip(x[\"Description\"], x[\"Price\"]))\n",
    ").reset_index().rename(columns={0: \"Estimativas\"})\n",
    "\n",
    "# 6. Refiltra pelos RideID em comum\n",
    "dfCoords[\"RideID\"] = dfCoords[\"RideID\"].astype(str)\n",
    "dfEstimadaSelecionada[\"RideID\"] = dfEstimadaSelecionada[\"RideID\"].astype(str)\n",
    "ids_comuns = set(dfTempo[\"RideID\"]) & set(dfCoords[\"RideID\"]) & set(dfEstimadaSelecionada[\"RideID\"])\n",
    "\n",
    "dfTempo = dfTempo[dfTempo[\"RideID\"].isin(ids_comuns)].sort_values(\"RideID\").reset_index(drop=True)\n",
    "dfCoords = dfCoords[dfCoords[\"RideID\"].isin(ids_comuns)].sort_values(\"RideID\").reset_index(drop=True)\n",
    "dfEstimadaSelecionada = dfEstimadaSelecionada[dfEstimadaSelecionada[\"RideID\"].isin(ids_comuns)].sort_values(\"RideID\").reset_index(drop=True)\n",
    "\n",
    "# 7. Junta tudo sem merge (concatenando os DataFrames horizontalmente)\n",
    "dfDerivado = pd.concat([\n",
    "    dfTempo,\n",
    "    dfCoords.drop(columns=[\"RideID\"]),\n",
    "    dfEstimadaSelecionada.drop(columns=[\"RideID\"])\n",
    "], axis=1)\n",
    "\n",
    "# 8. Remove NaNs nas coordenadas\n",
    "dfDerivado = dfDerivado.dropna(subset=[\"Lat1\", \"Lng1\", \"Lat2\", \"Lng2\"]).reset_index(drop=True)\n",
    "\n",
    "# 9. C√°lculo da dist√¢ncia\n",
    "dfDerivado[\"Distancia_km\"] = dfDerivado.apply(\n",
    "    lambda row: geodesic((row[\"Lat1\"], row[\"Lng1\"]), (row[\"Lat2\"], row[\"Lng2\"])).kilometers,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Mostrar amostra do DataFrame final com estimativas e valor_uber\n",
    "print(\"\\nüìä Exemplo de dados do dfDerivado com estimativas:\")\n",
    "print(dfDerivado.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2060b2e7-0eab-4f72-b160-b251c8f3763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Treinando modelos para servi√ßos da Uber (com features auxiliares):\n",
      "\n",
      "üîÆ Iniciando modelo para: UberX\n",
      "‚úÖ Modelo treinado para: UberX\n",
      " ‚Üí MAE  : R$0.48\n",
      " ‚Üí RMSE : R$2.25\n",
      " ‚Üí R¬≤   : 0.9906\n",
      "\n",
      "üîÆ Iniciando modelo para: Comfort\n",
      "‚úÖ Modelo treinado para: Comfort\n",
      " ‚Üí MAE  : R$2.20\n",
      " ‚Üí RMSE : R$4.87\n",
      " ‚Üí R¬≤   : 0.9808\n",
      "\n",
      "üîÆ Iniciando modelo para: Black\n",
      "‚úÖ Modelo treinado para: Black\n",
      " ‚Üí MAE  : R$1.82\n",
      " ‚Üí RMSE : R$4.87\n",
      " ‚Üí R¬≤   : 0.9851\n",
      "\n",
      "üìä Resumo Final dos Modelos:\n",
      "Servi√ßo  Registros  MAE  RMSE     R¬≤\n",
      "  UberX     235601 0.48  2.25 0.9906\n",
      "  Black     123666 1.82  4.87 0.9851\n",
      "Comfort     192876 2.20  4.87 0.9808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# üöó Lista de servi√ßos da Uber a prever\n",
    "servicos_alvo = [\"UberX\", \"Comfort\", \"Black\"]\n",
    "\n",
    "print(\"üìà Treinando modelos para servi√ßos da Uber (com features auxiliares):\\n\")\n",
    "\n",
    "# Lista para armazenar os resultados\n",
    "resultados = []\n",
    "\n",
    "for servico in servicos_alvo:\n",
    "    print(f\"üîÆ Iniciando modelo para: {servico}\")\n",
    "\n",
    "    # Filtra somente onde o servi√ßo alvo tem valor\n",
    "    df_modelo = dfDerivado[dfDerivado[\"Estimativas\"].apply(\n",
    "        lambda d: isinstance(d, dict) and servico in d and isinstance(d[servico], (int, float))\n",
    "    )].copy()\n",
    "\n",
    "    if df_modelo.empty:\n",
    "        print(f\"‚ö†Ô∏è Nenhum dado encontrado para {servico}. Ignorado.\\n\")\n",
    "        continue\n",
    "\n",
    "    # Define a vari√°vel alvo\n",
    "    df_modelo[\"y\"] = df_modelo[\"Estimativas\"].apply(lambda d: d[servico])\n",
    "\n",
    "    # Features base\n",
    "    features_base = [\"Distancia_km\", \"Dia\", \"Hora\", \"HoraDecimal\", \"Lat1\", \"Lng1\", \"Lat2\", \"Lng2\"]\n",
    "\n",
    "    # Adiciona colunas auxiliares com os demais servi√ßos (exceto o alvo)\n",
    "    servicos_aux = set()\n",
    "    df_modelo[\"Estimativas\"].apply(lambda d: servicos_aux.update(d.keys()) if isinstance(d, dict) else None)\n",
    "    servicos_aux.discard(servico)\n",
    "\n",
    "    for s in servicos_aux:\n",
    "        nome_coluna = f\"aux_{s.lower().replace(' ', '_')}\"\n",
    "        df_modelo[nome_coluna] = df_modelo[\"Estimativas\"].apply(lambda d: d.get(s) if isinstance(d, dict) else np.nan)\n",
    "\n",
    "    # Prepara X e y\n",
    "    features_auxiliares = [col for col in df_modelo.columns if col.startswith(\"aux_\")]\n",
    "    X = df_modelo[features_base + features_auxiliares].fillna(-1)\n",
    "    y = df_modelo[\"y\"]\n",
    "\n",
    "    # Verifica√ß√£o m√≠nima de dados\n",
    "    if len(X) < 100:\n",
    "        print(f\"‚ö†Ô∏è Servi√ßo '{servico}' com poucos dados ap√≥s prepara√ß√£o ({len(X)} linhas) ‚Äî ignorado.\\n\")\n",
    "        continue\n",
    "\n",
    "    # Treinamento\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    modelo = RandomForestRegressor(random_state=42)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    # M√©tricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    resultados.append({\n",
    "        \"Servi√ßo\": servico,\n",
    "        \"Registros\": len(X),\n",
    "        \"MAE\": round(mae, 2),\n",
    "        \"RMSE\": round(rmse, 2),\n",
    "        \"R¬≤\": round(r2, 4)\n",
    "    })\n",
    "\n",
    "    print(f\"‚úÖ Modelo treinado para: {servico}\")\n",
    "    print(f\" ‚Üí MAE  : R${mae:.2f}\")\n",
    "    print(f\" ‚Üí RMSE : R${rmse:.2f}\")\n",
    "    print(f\" ‚Üí R¬≤   : {r2:.4f}\\n\")\n",
    "\n",
    "# üîö Resumo final\n",
    "if resultados:\n",
    "    df_resultados = pd.DataFrame(resultados).sort_values(by=\"R¬≤\", ascending=False)\n",
    "    print(\"üìä Resumo Final dos Modelos:\")\n",
    "    print(df_resultados.to_string(index=False))\n",
    "else:\n",
    "    print(\"‚ùå Nenhum modelo foi treinado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c7f66d4-d201-4e3a-b88e-54451c06832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash\n",
      "  Downloading dash-3.0.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting dash-bootstrap-components\n",
      "  Downloading dash_bootstrap_components-2.0.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting jupyter-dash\n",
      "  Downloading jupyter_dash-0.4.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dash) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dash) (3.0.3)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dash) (5.24.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dash) (7.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dash) (4.11.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dash) (2.32.3)\n",
      "Collecting retrying (from dash)\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dash) (1.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from dash) (75.1.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from jupyter-dash) (8.27.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from jupyter-dash) (6.28.0)\n",
      "Collecting ansi2html (from jupyter-dash)\n",
      "  Downloading ansi2html-1.9.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash) (1.6.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash) (8.2.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from plotly>=5.0.0->dash) (24.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from Werkzeug<3.1->dash) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from importlib-metadata->dash) (3.17.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (0.1.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipykernel->jupyter-dash) (5.14.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from ipython->jupyter-dash) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests->dash) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests->dash) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests->dash) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from requests->dash) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.7.0 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from retrying->dash) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->jupyter-dash) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter-dash) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter-dash) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter-dash) (305.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->jupyter-dash) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from stack-data->ipython->jupyter-dash) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from stack-data->ipython->jupyter-dash) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\mathe\\anaconda3\\lib\\site-packages (from stack-data->ipython->jupyter-dash) (0.2.2)\n",
      "Downloading dash-3.0.4-py3-none-any.whl (7.9 MB)\n",
      "   ---------------------------------------- 0.0/7.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.1/7.9 MB 13.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.7/7.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.1/7.9 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.9/7.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.9/7.9 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading dash_bootstrap_components-2.0.2-py3-none-any.whl (202 kB)\n",
      "Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
      "Downloading ansi2html-1.9.2-py3-none-any.whl (17 kB)\n",
      "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: retrying, ansi2html, dash, dash-bootstrap-components, jupyter-dash\n",
      "Successfully installed ansi2html-1.9.2 dash-3.0.4 dash-bootstrap-components-2.0.2 jupyter-dash-0.4.2 retrying-1.3.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install dash dash-bootstrap-components jupyter-dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9297368b-a52c-46a8-bf6d-b595fbc1ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Simular dfDerivado com colunas m√≠nimas\n",
    "nomes_dias = ['Segunda', 'Ter√ßa', 'Quarta', 'Quinta', 'Sexta', 'S√°bado', 'Domingo']\n",
    "servicos = [\"UberX\", \"Comfort\", \"Black\"]\n",
    "\n",
    "# Aqui est√° um exemplo base que voc√™ substituir√° pelo seu dfDerivado real:\n",
    "dfDerivado = dfDerivado.copy()  # <- use seu dfDerivado real aqui\n",
    "\n",
    "df_dashboard_final = pd.DataFrame()\n",
    "\n",
    "for servico in servicos:\n",
    "    df_modelo = dfDerivado[dfDerivado[\"Estimativas\"].apply(\n",
    "        lambda d: isinstance(d, dict) and servico in d and isinstance(d[servico], (int, float))\n",
    "    )].copy()\n",
    "\n",
    "    if df_modelo.empty:\n",
    "        continue\n",
    "\n",
    "    df_modelo[\"y\"] = df_modelo[\"Estimativas\"].apply(lambda d: d[servico])\n",
    "    y = df_modelo[\"y\"]\n",
    "\n",
    "    features_base = [\"Distancia_km\", \"Dia\", \"Hora\", \"HoraDecimal\", \"Lat1\", \"Lng1\", \"Lat2\", \"Lng2\"]\n",
    "    X = df_modelo[features_base].fillna(-1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    modelo = RandomForestRegressor(random_state=42)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "\n",
    "    df_resultado = X_test.copy()\n",
    "    df_resultado[\"valor_real\"] = y_test\n",
    "    df_resultado[\"valor_previsto\"] = y_pred\n",
    "    df_resultado[\"servico\"] = servico\n",
    "    df_resultado[\"hora\"] = df_resultado[\"Hora\"]\n",
    "    df_resultado[\"dia_nome\"] = df_resultado[\"Dia\"].map(dict(enumerate(nomes_dias)))\n",
    "\n",
    "    df_dashboard_final = pd.concat([df_dashboard_final, df_resultado], ignore_index=True)\n",
    "    df_dashboard_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22264add-1f6f-4fbc-9423-d23310a4b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\anaconda3\\Lib\\site-packages\\dash\\dash.py:587: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x21049742660>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html, Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "\n",
    "# df_dashboard_final deve estar carregado do c√≥digo anterior\n",
    "\n",
    "app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "servicos_disponiveis = df_dashboard_final[\"servico\"].unique()\n",
    "dias_disponiveis = df_dashboard_final[\"dia_nome\"].unique()\n",
    "\n",
    "app.layout = dbc.Container([\n",
    "    html.H2(\"üìä Compara√ß√£o de Pre√ßo Real vs Previsto\", className=\"text-center my-4\"),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Label(\"Servi√ßo:\"),\n",
    "            dcc.RadioItems(\n",
    "                id='filtro_servico',\n",
    "                options=[{'label': s, 'value': s} for s in servicos_disponiveis],\n",
    "                value=servicos_disponiveis[0],\n",
    "                inline=True\n",
    "            )\n",
    "        ], width=12)\n",
    "    ], className=\"mb-3\"),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Label(\"Dia da Semana:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='filtro_dia',\n",
    "                options=[{'label': d, 'value': d} for d in dias_disponiveis],\n",
    "                value='Segunda',\n",
    "                clearable=False\n",
    "            )\n",
    "        ], width=4),\n",
    "\n",
    "        dbc.Col([\n",
    "            html.Label(\"Tipo de Gr√°fico:\"),\n",
    "            dcc.Dropdown(\n",
    "                id='tipo_grafico',\n",
    "                options=[\n",
    "                    {'label': 'Dispers√£o', 'value': 'dispersao'},\n",
    "                    {'label': 'Barras', 'value': 'barras'}\n",
    "                ],\n",
    "                value='dispersao',\n",
    "                clearable=False\n",
    "            )\n",
    "        ], width=4)\n",
    "    ], className=\"mb-4\"),\n",
    "\n",
    "    dcc.Graph(id='grafico_resultado')\n",
    "\n",
    "], fluid=True)\n",
    "\n",
    "@app.callback(\n",
    "    Output('grafico_resultado', 'figure'),\n",
    "    [Input('filtro_servico', 'value'),\n",
    "     Input('filtro_dia', 'value'),\n",
    "     Input('tipo_grafico', 'value')]\n",
    ")\n",
    "def atualizar_grafico(servico, dia, tipo_grafico):\n",
    "    df_filtrado = df_dashboard_final[\n",
    "        (df_dashboard_final['servico'] == servico) &\n",
    "        (df_dashboard_final['dia_nome'] == dia)\n",
    "    ]\n",
    "\n",
    "    if tipo_grafico == 'dispersao':\n",
    "        fig = px.scatter(\n",
    "            df_filtrado, x='valor_real', y='valor_previsto',\n",
    "            color='hora',\n",
    "            labels={'valor_real': 'Valor Real', 'valor_previsto': 'Valor Previsto'},\n",
    "            title=f\"{servico} - {dia} (Dispers√£o)\",\n",
    "            hover_data=['hora']\n",
    "        )\n",
    "    else:\n",
    "        df_bar = df_filtrado.reset_index(drop=True).head(20)\n",
    "        fig = px.bar(\n",
    "            df_bar, x=df_bar.index,\n",
    "            y=['valor_real', 'valor_previsto'],\n",
    "            barmode='group',\n",
    "            labels={'value': 'Valor', 'index': 'Corrida'},\n",
    "            title=f\"{servico} - {dia} (Barras)\"\n",
    "        )\n",
    "\n",
    "    fig.update_layout(template='plotly_white')\n",
    "    return fig\n",
    "\n",
    "# Rodar o app\n",
    "app.run(mode='inline', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140a46d-aa10-40a7-ad3f-44d4190cb583",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
